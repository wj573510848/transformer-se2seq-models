论文：Accelerating Neural Transformer via an Average Attention Network
链接：https://arxiv.org/pdf/1805.00631.pdf

主要改动：
1.将decoder的self attention layer改为aan layer
2.改写beam search解码函数

使用：
1.python train.py #训练
2.python release.py #release
3.python test.py #测试


